<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Big Face Cat</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="记录自己的一些感悟以及分享">
<meta property="og:type" content="website">
<meta property="og:title" content="Big Face Cat">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Big Face Cat">
<meta property="og:description" content="记录自己的一些感悟以及分享">
<meta property="og:locale">
<meta property="article:author" content="Lime">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Big Face Cat" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.0.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Big Face Cat</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-druid中GroupbyQuery查询流程解析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2022-02-19T14:23:52.000Z" itemprop="datePublished">2022-02-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/">druid中GroupbyQuery查询流程解析</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h4 id="整体概述"><a href="#整体概述" class="headerlink" title="整体概述"></a>整体概述</h4><p>​    从之前broker和his等节点对流程可知，对于所有的查询不同处在于构建的queryRunner不同，queryRunner本身可以看做一个函数，不同的查询类型对应的queryRunner不同，这一节将对其中几个查询类型进行解析，详解各种查询是如何进行的。</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219221718521.png" alt="image-20220219221718521"></p>
<p>​    在his端和realtime端的查询步骤如上图所示，整体处理逻需要关注的三个方法是：</p>
<ul>
<li><p>​    QueryFactory.createRunner</p>
</li>
<li><p>​    QueryFactory.mergeRunners</p>
</li>
<li><p>​    QueryToolChest.mergeResult</p>
<p>在查询流程当中，会按照先后顺序调用这三个方法，返回broker端之后还会掉用一次QueryToolChest.mergeResult方法将各个节点的结果再进行一次merge。所以下面的代码主要会解析不同查询中这三个方法的执行逻辑。</p>
</li>
</ul>
<p>​    groupByQueryRunner根据query会选择对应的strategy，一般来说，默认会选择v2版本，可以在配置文件中指定druid.lucene.query.groupBy.defaultStrategy来指定默认的策略。这里也只会对V2版本策略进行一个说明，groupbQueryFactory调用createRunner方法查询的会调用GroupByStrategy的process进行，现在对GroupByStrategyV2的策略进行说明，执行入口是GroupByQueryEngineV2.process()方法，跟其他查询一样也是会调用process方法对每个segment进行查询，然后调用factory.mergeRunners方法对QueryRunner集合进行聚合。</p>
<h4 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h4><h5 id="关键接口"><a href="#关键接口" class="headerlink" title="关键接口"></a>关键接口</h5><p>在对groupby的整个流程进行解析之前，先看看在druid在groupby中抽象出的两个类和接口，方便后续理解</p>
<ol>
<li><p>grouper接口</p>
</li>
<li><p>CloseableGrouperIterator</p>
</li>
</ol>
<p>​    首先是grouper接口：</p>
<p>​    grouper接口在整个groupby流程中的作用是对groupby的维度进行分组以及聚合计算。grouper接口的包含的方法和其内部接口如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222536470.png" alt="image-20220219222536470"></p>
<p>关键方法为：</p>
<ul>
<li>init方法：初始化Grouper对象</li>
<li>aggregate：使用提供的键值聚合当前行。</li>
<li>iterator：将完成聚合运算的所有行生成的groupby结果转换为可迭代的聚合结果。</li>
</ul>
<p>grouper使用的流程如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222559315.png" alt="image-20220219222559315"></p>
<p>​    其次是CloseableGrouperIterator接口，它是用于迭代groupby完成之后的结果数据，继承于Iterator接口，他的成员变量和构造方法如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222612118.png" alt="image-20220219222612118"></p>
<p>​    iterator是通过调用grouper.iterator方法生成，transformer变量是一个Function，这个接口用于将grouper生成的结果进行一个转化操作。</p>
<p>​    下面通过对groupby查询整体流程的一个解析来看看tindex是如何完成groupby操作的。</p>
<h5 id="GroupByQueryEngineV2-process解析"><a href="#GroupByQueryEngineV2-process解析" class="headerlink" title="GroupByQueryEngineV2.process解析"></a>GroupByQueryEngineV2.process解析</h5><p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222632657.png" alt="image-20220219222632657"></p>
<p>​    V2版本是基于堆外内存计算的，intermediateResultsBufferPool表示堆外内存池。</p>
<p>​    groupby每个segment的计算逻辑基本上是在GroupByQueryEngineV2这个类中，处理流程前半部分和TimeseriesQuery一样，通过对query中interval的解析获取cursors，通过cursors来操作数据，groupQuery查询会先根据要分组的维度通过cursor获取DimensionSelector集合，这些DimensionSelector用于查询维度字段的值，具体的groupby的逻辑在GroupByEngineIterator这个类中，接下来详细解读一下tindex是如何进行groupby的。</p>
<p>​    在CloseableGrouperIterator中，进行groupby之前要先调用initNewDelegate()，这里面会初始化Grouper对象，groupby的核心逻辑就封装在这个类中。</p>
<p>​    process方法整体流程如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222652499.png" alt="image-20220219222652499"></p>
<p>​    其中对cursor进行查询操作的操作如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222737925.png" alt="image-20220219222737925"></p>
<p>​    makeDimensionSelector方法是获得每个groupby字段的selector，这部分逻辑是将分组字段的查询器selector都构建出来，最终构建出GroupByEngineIterator，GroupByEngineIterator会封装对segment进行groupby的逻辑，下面篇幅将讲解GroupByEngineIterator中的逻辑，GroupByEngineIterator继承于Iterator，主要看next方法和hasnext方法，从中可以看到获取row是通过CloseableGrouperIterator对象。这个对象是从GroupByEngineIterator.initNewDelegate()方法创建得到，initNewDelegate流程如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222754027.png" alt="image-20220219222754027"></p>
<p>​    此方法会先初始化一个grouper，然后调用aggregateSingleValueDims或者aggregateMultiValueDims计算聚合结果，最后返回CloseableGrouperIterator,在tindex中使用groupby现在有两种grouper，分别是：BufferHashGrouper和BufferArrayGrouper，使用那种grouper是在代码中是通过GroupByQueryEngineV2.isArrayAggregateApplicable方法进行判断，使用BufferArrayGrouper的条件是groupby的维度只有一个，并且能够拿到这个维度的基数以及类型占用长度，同时当前的buffer容量能够支撑这些维度存储就会选用BufferArrayGrouper，其他情况下都会使用BufferHashGrouper。</p>
<p>​    其中，Grouper根据通常从ColumnSelectorFactory获得的行聚合度量，这些行位于某个外部驱动程序传入的分组键下。聚合完成后，它们还可以迭代分组行。它们的工作方式有点类似于键类型到聚合值的映射。Grouper接口如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222805541.png" alt="image-20220219222805541"></p>
<p>​    现在详解一下BufferHashGrouper实现,主要是计算出需要申请的内存大小，生成一个ByteBufferHashTable，这是一个hash表，用于存放各个分组的键和key值，开始查询之后会根据groupby的多列分区不同的分区会会被分步到这个hash表当中。它继承于AbstractBufferHashGrouper。</p>
<p>​    首先是构造方法：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222820888.png" alt="image-20220219222820888"></p>
<p>​    其中maxLoadFactor参数表示加载因子，就是hash表中存储的关键字个数，与可以散列位置的比值，这个值越大说明发生hash碰撞几率会越大。默认为0.7。initialBuckets表示初始化的桶的个数，在进行groupby的过程中，每个分组key组成的唯一值确定一个bucket。bucketSize表示每个bucket占用的字节大小，计算逻辑如上，比较简单就是一个HASH_SIZE（这里是int类型占用长度）+维度的数量+每个聚合函数结果占用的字节数量。</p>
<p>​    init方法：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222832663.png" alt="image-20220219222832663"></p>
<p>​    在init方法中主要是初始化hashTable，根据构造函数中已经初始化的配置参数信息，生成hashTable，主要步骤如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222847160.png" alt="image-20220219222847160"></p>
<ol>
<li>计算hashtable占用的size</li>
</ol>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222908342.png" alt="image-20220219222908342"></p>
<ol start="2">
<li>分别计算出hashTableBuffer和offsetList。</li>
</ol>
<p>​    hashTableBuffer表示整个hashtable的存储空间。</p>
<p>​    offsetList用于跟踪已用bucket的偏移量。当通过initializeNewBucketKey初始化新bucket时，将向该列表添加一个偏移量。</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222931539.png" alt="image-20220219222931539"></p>
<ol start="3">
<li><p>初始化hashTable(并非jdk中的hashtable，而是druid中使用堆外内存抽象出的hash表实现),在对grouper初始化完成之后，执行聚合计算</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219222958170.png" alt="image-20220219222958170"></p>
</li>
</ol>
<p>​    如果都是单值列进行聚合操作调用aggregateSingleValueDims方法，否则调用aggregateMultiValueDims方法，这里对HashAggregateIterator中的aggregateSingleValueDims方法进行一个解析：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223011452.png" alt="image-20220219223011452"></p>
<p>​    代码很简单，是对cursor对象进行一个迭代通过selectors查询出groupby的键值的id，构建keyBuffer，keybuffer中保存了当前的groupby的key信息，然后调用grouper的aggregate方法进行聚合，最后调用cursor.advance使cursor向前进一步。循环直到cursor无法迭代。</p>
<p>​    现在解析一下aggregate方法，aggregate方法是对数据进行聚合，底层调用的是</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223021255.png" alt="image-20220219223021255"></p>
<p>在BufferHashGrouper中的实现如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223029452.png" alt="image-20220219223029452"></p>
<p>​    入参key就是在aggregateSingleValueDims构建的keybuffer，而keyhash是将keybuffer进行hash之后的一个int值，方法首先会将keybuffer转化为一个bytebuffer并且对它进行一个校验，然后调用hashtable的findBucketWithAutoGrowth，拿到当前key对应的bucket位置。findBucketWithAutoGrowth是通过key值获取当前bucket位置，如果hashtable容量不够还会进行扩容，这里不做讲解。如果当前bucket还没有被占用，则调用initializeNewBucketKey初始化一个新的bucketkey，并且调用当前query的所有aggregator的init方法对agg进行一个init初始化操作，最后再调用每个aggregator的aggregate方法进行运算。</p>
<p>​    聚合完成之后会返回一个可迭代的结果，通过如下方式</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223040244.png" alt="image-20220219223040244"></p>
<p>​    其中CloseableGrouperIterator实际上是对grouper的一个封装代理，实际上最终调用的还是grouper的迭代逻辑，grouper中的iterator方法可以生成一个可迭代对象，这个迭代对象即可以迭代出当前聚合查询完成之后的结果，在HashBufferGroup中有对应的实现（这里是不带排序的处理逻辑）：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223050272.png" alt="image-20220219223050272"></p>
<p>​    通过对offsetList的遍历拿到当前hashtable中存在的所有的数据并且通过bucketEntryForOffset生成Entry对象，Entry中保存了groupby之后的聚合结果。最后在通过CloseableGrouperIterator转化成为MapBasedRow返回。这就是整个groupby的process部分重要逻辑。</p>
<h5 id="GroupByMergingQueryRunnerV2-run解析"><a href="#GroupByMergingQueryRunnerV2-run解析" class="headerlink" title="GroupByMergingQueryRunnerV2.run解析"></a>GroupByMergingQueryRunnerV2.run解析</h5><p>​    在所有的QueryRunner创建完成之后，会调用QueryFactory的mergeRunners合并这些QueryRunners,具体实现为GroupByMergingQueryRunnerV2，在这之中的成员如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223115467.png" alt="image-20220219223115467"></p>
<ul>
<li>config：groupby查询的配置信息</li>
<li>queryables：需要进行merge的QueryRunner集合</li>
<li>exec：执行线程池</li>
<li>queryWatcher：用于QueryRunner级别运行时候注册查询。</li>
<li>concurrencyHint：当前jvm可用的cpu数量</li>
<li>mergeBufferPool：用于获取merge时所需要的ByteBuffer空间</li>
<li>mergeBufferSize：merge所需要的size</li>
<li>processingTmpDir：执行merge时使用的临时目录</li>
</ul>
<p>下面开始逐层剖析run方法：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223143477.png" alt="image-20220219223143477"></p>
<ol>
<li><p>判断是否可以使用ChainedExecutionQueryRunner来执行merge操作，前提条件是mergeRunnersUsingChainedExecution参数true或者bysegment参数为true（常用于test测试），使用ChainedExecutionQueryRunner类来执行merge不会申请额外的堆外内存，对某些特俗情况下有利于内存的节约（个人理解）。</p>
</li>
<li><p>构建combiningAggregatorFactories、temporaryStorageDirectory、当前查询优先级以及timeout等信息</p>
</li>
</ol>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223212039.png" alt="image-20220219223212039"></p>
<ol start="3">
<li><p>构建最终的BaseSequence，步骤分为以下几部：</p>
<pre><code>1. 首先初始化资源包括：临时的文件存储（temporaryStorage）  、mergeBuffer（合并结果使用的直接内存buffer）并且将这些资源都添加到resources集合中（用于在执行完成之后释放资源）。
</code></pre>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223244113.png" alt="image-20220219223244113"></p>
<pre><code> 2. 构建grouper和Accumulator。其中grouper作用之前已经讲过，而Accumulator可以看做一个累加器，其中封装了对数据进行累加计算的逻辑，在这里用于对groupby输入数据进行计算逻辑的封装。构建这两个对象使用的方法为RowBasedGrouperHelper.createGrouperAccumulatorPair方法，下面详解一下这个方法：
</code></pre>
</li>
</ol>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223302789.png" alt="image-20220219223302789"></p>
<p>入参列表如图所示，下面看具体实现逻辑.</p>
<ol>
<li>这部分是一些参数的初始化，包括limit信息，key的序列化器，columnSelectorFactory等</li>
</ol>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223320717.png" alt="image-20220219223320717"></p>
<ol start="2">
<li><p>构建grouper，根据concurrencyHint的值来构建grouper，concurrencyHint表示当前机器可用的cpu核数，当concurrencyHint=-1时构建SpillingGrouper，而其他情况构建ConcurrentGrouper来并发的执行grouper逻辑。在底层逻辑中ConcurrentGrouper中也是s维护了一个SpillingGrouper的集合来实现的并行计算，所以实际上他们最终都是使用SpillingGrouper。在SpillingGrouper中，最终使用的是BufferHashGrouper实现的，与BufferHashGrouper不同的是，SpillingGrouper在buffer内存使用满的时候会将之前的数据溢写到磁盘中，然后重置buffer来防止内存不足。</p>
</li>
<li><p>在构建grouper完成之后会构建Accumulator，这之中封装了对row进行处理的逻辑，详细代码如下：</p>
</li>
</ol>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223344867.png" alt="image-20220219223344867"></p>
<p>​    首先会对grouper进行一个init操作，调用columnSelectorFactory.setRow对columnSelectorFactory中的row进行设置，然后构建groupkey，最后调用grouper的aggregate方法进行聚合计算。逻辑比较简单。</p>
<ol start="4">
<li>在对grouper和Accumulator构建完成之后，就会将所有的QueryRunner提交执行了：</li>
</ol>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223413572.png" alt="image-20220219223413572"></p>
<p>通过这段代码将queryRunner集合迭代并且使用构建的Accumulator逻辑进行运算。</p>
<ol start="5">
<li>生成CloseableGrouperIterator并且返回，整个GroupByMergingQueryRunnerV2.run的逻辑就完成了。</li>
</ol>
<p><img src="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/image-20220219223434957.png" alt="image-20220219223434957"></p>
<h5 id="GroupByQueryQueryToolChest-mergeResults"><a href="#GroupByQueryQueryToolChest-mergeResults" class="headerlink" title="GroupByQueryQueryToolChest.mergeResults"></a>GroupByQueryQueryToolChest.mergeResults</h5><p>​    在完成mergeRunner之后还会调用mergeResults方法,此方法会将结果再进行一次聚合，在broker端和也会调用一次，逻辑是将上两步groupby结果在进行一次聚合。这里不做详细讲解。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/" data-id="ckzty1zzy0001qd7978z3gr55" data-title="druid中GroupbyQuery查询流程解析" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/druid/" rel="tag">druid</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-druid中TimeseriesQuery的查询源码解析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2022-02-19T14:13:19.000Z" itemprop="datePublished">2022-02-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/">druid中TimeseriesQuery的查询源码解析</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h4 id="整体概述"><a href="#整体概述" class="headerlink" title="整体概述"></a>整体概述</h4><p>​    从之前broker和his等节点对流程可知，对于所有的查询不同处在于构建的queryRunner不同，queryRunner本身可以看做一个函数，不同的查询类型对应的queryRunner不同，这一节将对其中几个查询类型进行解析，详解各种查询是如何进行的。</p>
<p><img src="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220219221718521.png" alt="image-20220219221718521"></p>
<p>​    在his端和realtime端的查询步骤如上图所示，整体处理逻需要关注的三个方法是：</p>
<ul>
<li><p>​    QueryFactory.createRunner</p>
</li>
<li><p>​    QueryFactory.mergeRunners</p>
</li>
<li><p>​    QueryToolChest.mergeResult</p>
<p>在查询流程当中，会按照先后顺序调用这三个方法，返回broker端之后还会掉用一次QueryToolChest.mergeResult方法将各个节点的结果再进行一次merge。所以下面的代码主要会解析不同查询中这三个方法的执行逻辑。</p>
</li>
</ul>
<p>​    对于需要统计一段时间内的汇总数据，或者是指定时间粒度的汇总数据，Druid通过Timeseries来完成。简单来说，只有聚合函数的查询一般都是TimeseriesQuery，比如select max(age),sum(account) from t1 这类查询。</p>
<h4 id="源码解析"><a href="#源码解析" class="headerlink" title="源码解析"></a>源码解析</h4><h5 id="QueryFactory-createRunner"><a href="#QueryFactory-createRunner" class="headerlink" title="QueryFactory.createRunner"></a>QueryFactory.createRunner</h5><p>​    从节点对请求的处理可知，每个不同的查询类型都有一个对应的QueryRunnerFactory，在TimeseriesQueryFactory中createRunner方法返回一个TimeseriesQueryRunner。执逻辑包含在，run方法如下</p>
<p><img src="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220219221838058.png" alt="image-20220219221838058"></p>
<p>​    TimeseriesQueryRunner的run方法，run方法调用TimeseriesQueryEngine的process方法，TimeseriesQuery查询的实际查询逻辑在TimeseriesQueryEngine中。</p>
<p>​    TimeseriesQueryEngine查询逻辑如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220219221851106.png" alt="image-20220219221851106"></p>
<p>​    上述流程是通过TimeseriesQueryRunnerFactory的mergeRunners调用，该方法里调用ChainedExecutionQueryRunner方法执行并行查询，他会并行执行所有的QueryRunner，并且将这些所有QueryRunner结果进行一个合并。ChainedExecutionQueryRunner在整体查询逻辑一节有讲到，大部分查询都可以使用ChainedExecutionQueryRunner的逻辑进行聚合。</p>
<p>​    下面详解一下process方法</p>
<p><img src="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220219221902916.png" alt="image-20220219221902916"></p>
<p>​    process方法前半部分都是在构建DirectLuceneCursor集合，DirectLuceneCursor接口如下</p>
<p><img src="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220219221913893.png" alt="image-20220219221913893"></p>
<p>通过queryAdapter.makeDirectCursors方法来构建DirectLuceneCursor是用于对segment进行查询的一个接口的封装,主要作用是执行聚合运算。后半部分具体的查询逻辑如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220219221927610.png" alt="image-20220219221927610"></p>
<p>​    通过对DirectLuceneCursor进行一个遍历,从query中获取所有的aggregator，然后调用DirectLuceneCursor的aggregateSearch方法对segment进行一个聚合运算，并且构建TimeseriesResultValue结果。</p>
<h5 id="QueryFactory-mergeRunners"><a href="#QueryFactory-mergeRunners" class="headerlink" title="QueryFactory.mergeRunners"></a>QueryFactory.mergeRunners</h5><p>​    TimeseriesQuery中使用ChainedExecutionQueryRunner来实现QueryFactory.mergeRunners的逻辑。</p>
<p>​    下面再看ChainedExecutionQueryRunner的实现，首先看构造函数：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220219222009197.png" alt="image-20220219222009197"></p>
<ul>
<li>queryables：表示本次需要merge的所有QueryRunner</li>
<li>exec：是执行线程池</li>
<li>queryWatcher：用于QueryRunner级别运行时候注册查询信息，可用于取消监视查询请求。</li>
</ul>
<p>整体的执行逻辑如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220219222028312.png" alt="image-20220219222028312"></p>
<p>​    这段逻辑比较简单就是将所有的QueryRunner调用run方法执行并且将结果返还然后调用创建一个MergeIterable将这些结果进行merge。</p>
<p><img src="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220219222042040.png" alt="image-20220219222042040"></p>
<h5 id="QueryFactoryToolChest-mergeResults"><a href="#QueryFactoryToolChest-mergeResults" class="headerlink" title="QueryFactoryToolChest.mergeResults"></a>QueryFactoryToolChest.mergeResults</h5><p>​    在TimeseriesResult中是继承与ResultMergeQueryRunner来实现mergeRunners的，ResultMergeQueryRunner是一个抽象类，如下所示</p>
<p><img src="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220219222115342.png" alt="image-20220219222115342"></p>
<p>​    继承此类需要实现两个方法makeOrdering和createMergeFn方法，这两个方法分别封装排序和合并的逻辑。</p>
<p>​    makeOrdering 表示排序的逻辑在Timeseries查询中排序的逻辑使用的是ResultGranularTimestampComparator，通过对查询结果的时间字段(__time进行一个排序)</p>
<p>​    合并逻辑使用的实现是TimeseriesBinaryFn，逻辑代码如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220219222127631.png" alt="image-20220219222127631"></p>
<p>​    调用aggregationFactory的combine方法对结果进行combine。</p>
<p>​    以上就是druid中TimeseriesQuery整体的一个查询逻辑，本文知识粗略的对部分关键源码进行一个分析，如需要深入请各位读者自己仔细阅读，希望 能给大家带来一定帮助</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" data-id="ckzty1zzx0000qd794rwd8h7q" data-title="druid中TimeseriesQuery的查询源码解析" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/druid/" rel="tag">druid</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-druid中的常用工具类" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/02/19/druid%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB/" class="article-date">
  <time class="dt-published" datetime="2022-02-19T13:56:47.000Z" itemprop="datePublished">2022-02-19</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/02/19/druid%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB/">druid中的常用工具类</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><h6 id="本篇博文将讲解在apache-druid中的关键的工具和他的抽象的封装，如果不理解这些很难去看懂源码。如果需要对apache-druid的源码进行学习，务必先弄懂这些，下面笔者将对这些进行源码解析。"><a href="#本篇博文将讲解在apache-druid中的关键的工具和他的抽象的封装，如果不理解这些很难去看懂源码。如果需要对apache-druid的源码进行学习，务必先弄懂这些，下面笔者将对这些进行源码解析。" class="headerlink" title="本篇博文将讲解在apache druid中的关键的工具和他的抽象的封装，如果不理解这些很难去看懂源码。如果需要对apache druid的源码进行学习，务必先弄懂这些，下面笔者将对这些进行源码解析。"></a>本篇博文将讲解在apache druid中的关键的工具和他的抽象的封装，如果不理解这些很难去看懂源码。如果需要对apache druid的源码进行学习，务必先弄懂这些，下面笔者将对这些进行源码解析。</h6><h4 id="Sequence与Yielder"><a href="#Sequence与Yielder" class="headerlink" title="Sequence与Yielder"></a>Sequence与Yielder</h4><p>​    Sequence和Yielder是整个查询中非常常见工具封装，如果不理解很难去看懂查询部分代码，下面对Sequence与Yielder进行一个讲解：</p>
<p>​    druid设计了一种可以迭代的序列叫Sequence，其实现在java-util包中。它是对Iterator操作的高级封装。但是它与普通的Iterator不同，它不会为您提供从中提取值的方式，而是提供了一个累加器（Accumulator）并定义数据如何操作。</p>
<p>​    这种控制反转（IoC）的方式是为了更好的让Sequence进行资源管理。当执行结束时，它可以强制调用close()方法来清除资源。如果没有这种反转，在操作时会很容易引起资源泄漏。</p>
<p>​    Sequence上还暴露了Yielder对象。它可以允许你在Sequence上遍历操作时进行中断，它会保存执行的状态，下次执行是在从终端处开始。它不会提供类似于Sequence的资源管理功能，需要显示的调用close方法。</p>
<p>​        首先来看一下Sequence接口的定义：</p>
<p><img src="/2022/02/19/druid%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB/image-20220219215833537.png" alt="image-20220219215833537"></p>
<p>它只提供了两个方法接口：</p>
<ol>
<li><p>accumulate方法的功能是通过控制反转的方式完成聚合运算。该方法的第一个参数为传入的初始值，Accumulator累加器是封装回调函数的接口，把原来在迭代过程中进行聚合运算的逻辑抽取到accumulate方法中回调执行。它的接口定义为：</p>
<p><img src="/2022/02/19/druid%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB/image-20220219215913278.png" alt="image-20220219215913278"></p>
</li>
</ol>
<p>​    以上的方法中的两个参数通过范型的方式设定：</p>
<p>​    第一个参数保存聚合的结果，在调用时作为参数传入，计算完成后将该参数作为结果返回，并在下一次迭代时作为参数传入，循环执行，知道迭代结束。其使用方法举例如下（取自BaseSequence类的makeYeilder方法）：</p>
<p><img src="/2022/02/19/druid%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB/image-20220219215928939.png" alt="image-20220219215928939"></p>
<p>​    第二个参数in是迭代器的下一个元素的值。举一个例子说明：假设AccumulatorType是Integer， in也是Integer。下面验证以下一个整数的Sequence是不是递增的，其实现方法如下：</p>
<p><img src="/2022/02/19/druid%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB/image-20220219215943998.png" alt="image-20220219215943998"></p>
<p>​    再一个完整的例子，取一个值为0 - 9的List的所有值的和：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">		List&lt;Integer&gt; intList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i ++) &#123;</span><br><span class="line">			intList.add(i);</span><br><span class="line">		&#125;</span><br><span class="line">		Sequence&lt;Integer&gt; intSequence = Sequences.simple(intList);</span><br><span class="line">		<span class="keyword">int</span> x = intSequence.accumulate(<span class="number">0</span>, <span class="keyword">new</span> Accumulator&lt;Integer, Integer&gt;() &#123;</span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> Integer <span class="title">accumulate</span><span class="params">(Integer accumulated, Integer in)</span> </span>&#123;</span><br><span class="line">				<span class="keyword">return</span> accumulated + in;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line">		System.out.println(x);</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>第二个方法为toYielder。它的功能是将Sequence转换成一个Yielder。Yielder对象可以看作是一个无法回溯的连标。调用Yielder的get()方法可以用来获取当前元素的值。通过调用next方法获取下一个Yielder对象。</li>
</ol>
<p>​    在toYielder方法中需要传入一个YieldingAccumulator，它和Yielder协同工作实现Java语言中的中    断／延续执行。  YieldingAccumulator的接口实现如下所示：</p>
<p><img src="/2022/02/19/druid%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB/image-20220219220046926.png" alt="image-20220219220046926"></p>
<p>​    从以上定义中可以看出，YieldingAccumulator添加了yield标志。yield标志的初始值为false，调用yield方法以后将该标志设置为true。yield标志的作用是退出当前的遍历迭代过程，并将Accumulator的值赋值给当前的Yielder。举个例子如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">		List&lt;Integer&gt; intList = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">		<span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">10</span>; i ++) &#123;</span><br><span class="line">			intList.add(i);</span><br><span class="line">		&#125;</span><br><span class="line">		Sequence&lt;Integer&gt; intSequence = Sequences.simple(intList)</span><br><span class="line">		Yielder&lt;Integer&gt; yielder = intSequence.toYielder(<span class="number">0</span>, </span><br><span class="line"><span class="keyword">new</span> YieldingAccumulator&lt;Integer, Integer&gt;() &#123;</span><br><span class="line">			<span class="meta">@Override</span></span><br><span class="line">			<span class="function"><span class="keyword">public</span> Integer <span class="title">accumulate</span><span class="params">(Integer accumulated, Integer in)</span> </span>&#123;</span><br><span class="line">				yield();</span><br><span class="line">				<span class="keyword">return</span> accumulated + in;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;);</span><br><span class="line">		<span class="keyword">while</span>(!yielder.isDone()) &#123;</span><br><span class="line">			<span class="keyword">int</span> x = yielder.get();</span><br><span class="line">			System.out.println(x);</span><br><span class="line">			Yielder&lt;Integer&gt; oldYielder = yielder;</span><br><span class="line">			yielder = oldYielder.next(x);</span><br><span class="line">			oldYielder.close();</span><br><span class="line">		&#125;</span><br><span class="line">		yielder.close();</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<p>​    Sequence是怎么构造的呢？它是由工具类Sequences来创建的。具体代码在：io.druid.java.util.common.guava.Sequences</p>
<p>具体包含的方法如下</p>
<p><img src="/2022/02/19/druid%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB/image-20220219220148210.png" alt="image-20220219220148210"></p>
<p>下面看一下这个工具类里的一些常用的方法：</p>
<p>- simple：传入一个iterable接口的对象。返回一个BaseSequence对象。</p>
<p>- concat：把多个Sequence合并成一个。为了减少内存的使用，并不会把多个Sequence中的元素复制到一个新的Sequence，而是在执行accumulate方法时将多个Sequence的积累结果合并在一起。</p>
<p>- map：类似于函数式编程中的map函数，在执行accumulate方法时，在调用转换函数以后再进行聚合操作。</p>
<p>- filter：其功能是在执行accumulated方法时根据传入的Predicate过滤，如果Predicate返回true，则进行累加，否则放弃。GroupBy查询的Having就是使用该方法实现的。</p>
<p>- withEffect：在执行accumulate方法时异步执行某些逻辑，例如在CachingQueryRunner中异步的将Sequence中的元素收集到一个List中，待accumulate方法执行完成在进行缓存操作</p>
<p>- withBaggage：传入一个Closeable的实现类，一般用于对资源的关闭，防止内存泄露</p>
<h4 id="Guice在druid中的应用"><a href="#Guice在druid中的应用" class="headerlink" title="Guice在druid中的应用"></a>Guice在druid中的应用</h4><h5 id="与Spring的对比"><a href="#与Spring的对比" class="headerlink" title="与Spring的对比"></a>与Spring的对比</h5><p>​    Guice与Spring没有直接竞争关系，Spring是复杂的技术栈，而Guice只专注于依赖注入。Guice与Spring的表现方式也稍微有所区别。Guice觉得基于xml的方式过于隐晦，而自动注入(AutoWired)又过于灵活，所以Guice基于代码绑定实现，较为克制。而基于Module的方式让Guice获得了巨大的灵活性与可复用性，可以简单理解为多个xml装配，但更加强大，可复用。</p>
<h6 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GuiceExample</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">( String[] args )</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Injector injector = Guice.createInjector(<span class="keyword">new</span> Module() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Binder binder)</span> </span>&#123;</span><br><span class="line">                binder.bind(ProduceService.class).to(KafkaPrduceService.class);</span><br><span class="line">          binder.bind(String.class).annotatedWith(Names.named(<span class="string">&quot;server&quot;</span>)).toInstance(<span class="string">&quot;localhost:9002&quot;</span>);</span><br><span class="line">                binder.bind(String.class).annotatedWith(Names.named(<span class="string">&quot;topic&quot;</span>)).toInstance(<span class="string">&quot;test&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        ProduceService produce = injector.getInstance(ProduceService.class);</span><br><span class="line">        produce.produce(<span class="string">&quot;hello guice&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ProduceService</span> </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">produce</span><span class="params">(Object msg)</span></span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Singleton</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">KafkaPrduceService</span> <span class="keyword">implements</span> <span class="title">ProduceService</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> String server;</span><br><span class="line">        <span class="keyword">private</span> String topic;</span><br><span class="line">        <span class="meta">@Inject</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">KafkaPrduceService</span><span class="params">(<span class="meta">@Named(&quot;server&quot;)</span> String server, <span class="meta">@Named(&quot;topic&quot;)</span> String topic)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.server = server;</span><br><span class="line">            <span class="keyword">this</span>.topic = topic;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">produce</span><span class="params">(Object msg)</span> </span>&#123;</span><br><span class="line">            log.info(<span class="string">&quot;produce &#123;&#125;-&#123;&#125;-&#123;&#125;&quot;</span>, server, topic, msg);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​    我们看到guice中的绑定关系是在Module中维护的，可以简单当做是spring的xml文件。Singleton代表该服务是单例的，通过@Inject注入需要的bean，如果需要的bean没有绑定，会通过默认构造函数实例化。其它基本介绍可参考guice文档</p>
<h6 id="覆盖已有绑定关系"><a href="#覆盖已有绑定关系" class="headerlink" title="覆盖已有绑定关系"></a>覆盖已有绑定关系</h6><p>​    druid好多模块是可以自定义替换的，一方面通过spi机制+ClassLoader加载扩展模块实现模块热插拔，另一方面通过Guice覆盖绑定关系将新实现注入到框架。下面要介绍的就是guice的覆盖绑定关系能力。</p>
<p>看下面这个例子</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GuiceOverrideExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    List&lt;Module&gt; builtIns = ImmutableList.of(binder -&gt; &#123;</span><br><span class="line">      binder.bind(Service.class).to(BuiltinService.class);</span><br><span class="line">    &#125;);</span><br><span class="line"><span class="comment">//    List&lt;Module&gt; customs = ImmutableList.of();</span></span><br><span class="line">    List&lt;Module&gt; customs = ImmutableList.of(binder -&gt; &#123;</span><br><span class="line">      binder.bind(Service.class).to(CustomService.class);</span><br><span class="line">    &#125;);</span><br><span class="line">    Injector injector = Guice.createInjector(Modules.override(builtIns).with(customs));</span><br><span class="line">    FrameWork frameWork = injector.getInstance(FrameWork.class);</span><br><span class="line">    frameWork.start();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FrameWork</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Service service;</span><br><span class="line">    <span class="meta">@Inject</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FrameWork</span><span class="params">(Service service)</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.service = service;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">this</span>.service.run();</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Service</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">BuiltinService</span> <span class="keyword">implements</span> <span class="title">Service</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;BuiltinService&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomService</span> <span class="keyword">implements</span> <span class="title">Service</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      System.out.println(<span class="string">&quot;CustomService&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>​    我们看到框架本来绑定的是BuiltinService，现在我们需要替换成CustomService，只需要Modules.override即可覆盖绑定关系。</p>
<h6 id="默认绑定"><a href="#默认绑定" class="headerlink" title="默认绑定"></a>默认绑定</h6><p>​    在做基础库的时候，有时会依赖一些服务，但这些服务很可能被用户自定义，这时可以使用guice的默认绑定功能。</p>
<p>看下面代码:</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">GuiceOptionalBinderExample</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">  Injector injector = Guice.createInjector(<span class="keyword">new</span> FrameWorkModule(), <span class="keyword">new</span> Module() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Binder binder)</span> </span>&#123;</span><br><span class="line">      <span class="comment">//覆盖框架默认实现</span></span><br><span class="line">      <span class="comment">//如果需要传递参数，可以1.Inject 2.使用Provider</span></span><br><span class="line">      OptionalBinder.newOptionalBinder(binder, Emit.class).setBinding().to(kafkaEmit.class);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;);</span><br><span class="line">  TestService testService = injector.getInstance(TestService.class);</span><br><span class="line">  testService.test();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TestService</span> </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> Emit emit;</span><br><span class="line">  <span class="meta">@Inject</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">TestService</span><span class="params">(Emit emit)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.emit = emit;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.emit.emit(<span class="string">&quot;start TestService&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//-------应用代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">kafkaEmit</span> <span class="keyword">implements</span> <span class="title">Emit</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">emit</span><span class="params">(Object object)</span> </span>&#123;</span><br><span class="line">    log.info(<span class="string">&quot;kafkaEmit emit&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//-------库代码</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">FrameWorkModule</span> <span class="keyword">implements</span> <span class="title">Module</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Binder binder)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//库默认实现</span></span><br><span class="line">    OptionalBinder.newOptionalBinder(binder, Emit.class).setDefault().to(HttpEmit.class);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Emit</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">emit</span><span class="params">(Object object)</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">HttpEmit</span> <span class="keyword">implements</span> <span class="title">Emit</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">emit</span><span class="params">(Object object)</span> </span>&#123;</span><br><span class="line">    log.info(<span class="string">&quot;HttpEmit emit&quot;</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h6 id="Druid中的应用"><a href="#Druid中的应用" class="headerlink" title="Druid中的应用"></a>Druid中的应用</h6><p>​    在Druid中有几个通用的Guice扩展，不了解会对代码阅读产生影响。</p>
<table>
<thead>
<tr>
<th>模块</th>
<th>功能</th>
</tr>
</thead>
<tbody><tr>
<td>guice-lifecycle</td>
<td>实现生命周期托管，实现服务start、stop方法</td>
</tr>
<tr>
<td>guice-jsonconfig</td>
<td>Properties配置文件bean自动装配</td>
</tr>
<tr>
<td>guice-jersey-jetty</td>
<td>内嵌jetty的jersey Restful</td>
</tr>
</tbody></table>
<ol>
<li><p>guice-lifecycle</p>
<p>LifecycleModule提供服务托管能力，提供了4级服务优先级，框架会自动调用start和stop方法。该功能在druid应用非常广泛，是应用启动的原点。</p>
<p>如在CliBroker类中主动注册DruidBroker的生命周期</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CliBroker</span> <span class="keyword">extends</span> <span class="title">ServerRunnable</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">protected</span> List&lt;? extends Module&gt; getModules()</span><br><span class="line">  &#123;</span><br><span class="line">    List&lt;Module&gt; modules = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    modules.addAll(ImmutableList.of(</span><br><span class="line">        <span class="keyword">new</span> Module()</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="meta">@Override</span></span><br><span class="line">          <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Binder binder)</span></span></span><br><span class="line"><span class="function">          </span>&#123;</span><br><span class="line">             <span class="comment">//注册</span></span><br><span class="line">            LifecycleModule.register(binder, DruidBroker.class);</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="keyword">new</span> LookupModule()</span><br><span class="line">    ));</span><br><span class="line">    installSqlModule(modules);</span><br><span class="line">    <span class="keyword">return</span> modules;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>guice-jsonconfig</p>
<p>jsonconfig提供了配置文件bean自动装配，并支持validation注解校验。Druid中读取配置功能都使用了该功能。</p>
<p>如在CliBroker中配置缓存相关的配置</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CliBroker</span> <span class="keyword">extends</span> <span class="title">ServerRunnable</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">protected</span> List&lt;? extends Module&gt; getModules()</span><br><span class="line">  &#123;</span><br><span class="line">    List&lt;Module&gt; modules = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    modules.addAll(ImmutableList.of(</span><br><span class="line">        <span class="keyword">new</span> Module()</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="meta">@Override</span></span><br><span class="line">          <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Binder binder)</span></span></span><br><span class="line"><span class="function">          </span>&#123;</span><br><span class="line">             <span class="comment">//配置</span></span><br><span class="line">            JsonConfigProvider.bind(binder, <span class="string">&quot;druid.broker.cache&quot;</span>, CacheConfig.class);</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="keyword">new</span> LookupModule()</span><br><span class="line">    ));</span><br><span class="line">    installSqlModule(modules);</span><br><span class="line">    <span class="keyword">return</span> modules;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>guice-jersey-jetty</li>
</ol>
</li>
</ol>
<p>​    jersey-jetty提供了内嵌jetty的jersey Restful。Druid中http接口都由jersey支持，由Jetty充当servlet容器。</p>
<p>如在CliBroker中注册QueryResource</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CliBroker</span> <span class="keyword">extends</span> <span class="title">ServerRunnable</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">protected</span> List&lt;? extends Module&gt; getModules()</span><br><span class="line">  &#123;</span><br><span class="line">    List&lt;Module&gt; modules = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    modules.addAll(ImmutableList.of(</span><br><span class="line">        <span class="keyword">new</span> Module()</span><br><span class="line">        &#123;</span><br><span class="line">          <span class="meta">@Override</span></span><br><span class="line">          <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Binder binder)</span></span></span><br><span class="line"><span class="function">          </span>&#123;</span><br><span class="line">             <span class="comment">//注册QueryResource为jetty的入口</span></span><br><span class="line">            Jerseys.addResource(binder, QueryResource.class);</span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="keyword">new</span> LookupModule()</span><br><span class="line">    ));</span><br><span class="line">    installSqlModule(modules);</span><br><span class="line">    <span class="keyword">return</span> modules;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>​    本文对apache druid中的公共特殊作用的一些工具类，以及druid对guice的使用做了一个简单介绍，在阅读druid源码之前，需要对这部分的知识加以了解才能更好的去对源码进行一个阅读，希望各位读者通过这篇文章能对自己阅读druid源码时候能有一些帮助。相关问题的也可以联系笔者邮箱一起交流 - -。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/02/19/druid%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB/" data-id="ckztx6xtl000024794x9e69kn" data-title="druid中的常用工具类" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/druid/" rel="tag">druid</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-APACHE-DRUID-查询过程源码解析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2022-02-11T15:05:04.000Z" itemprop="datePublished">2022-02-11</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/">APACHE DRUID 查询过程源码解析</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="APACHE-DRUID-查询过程源码解析"><a href="#APACHE-DRUID-查询过程源码解析" class="headerlink" title="APACHE DRUID 查询过程源码解析"></a>APACHE DRUID 查询过程源码解析</h2><p>​        Apache Druid 是一个集时间序列数据库、数据仓库和全文检索系统特点于一体的分析性数据平台。本文将从整体到源码级别讲解整个查询流程</p>
<h3 id="整体查询逻辑架构"><a href="#整体查询逻辑架构" class="headerlink" title="整体查询逻辑架构"></a>整体查询逻辑架构</h3><p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211222352338.png" alt="image-20220211222352338"></p>
<p>​    druid最原生的查询方式是通过http进行查询，也可以通过sql查询，sql支持大部分查询，但是部分语法只能通过http的方式查询，本节将对druid的http整体的查询流程进行分析，方便开发者理解。</p>
<p>​    用户在发送查询请求到broker端之后，broker节点会对请求进行解析处理（主要根据查询的interval和segment将查询拆分成多个子查询）之后发送到对应的his节点和实时task进行查询。最后再将所有的数据结果合并返回用户。</p>
<h3 id="broker查询流程"><a href="#broker查询流程" class="headerlink" title="broker查询流程"></a>broker查询流程</h3><p>​    broker端的查询流程主要是根据查询的interval转换成不同segement的子查询发送到his端和task端，并根据它们返回数据结果进行合并，最后返回给用户。</p>
<h4 id="broker初始化"><a href="#broker初始化" class="headerlink" title="broker初始化"></a>broker初始化</h4><p>在开始理解broker的查询前，需要先了解broker的初始化过程。broker初始化相关代码主要在CliBroker类中。</p>
<p>初始化过程主要加载了以下module:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CacheModule</span><br><span class="line">LookupModule</span><br><span class="line">SqlModule</span><br><span class="line">MySQLProtocolModule</span><br></pre></td></tr></table></figure>

<ul>
<li><p> CacheModule：主要用于查询结果的缓存；</p>
</li>
<li><p> LookupModule：主要用于分群id数据的读写；</p>
</li>
<li><p> SqlModule：主要用于支持原生社区版的sql查询；</p>
</li>
<li><p> MySQLProtocolModule：主要用于支持MySQL协议版的sql查询。</p>
</li>
</ul>
<p>  请求整体的时序图如下：</p>
<p>  <img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211223604776.png" alt="image-20220211223604776"></p>
<p>请求代码处理逻辑：</p>
<ul>
<li>QueryResource的doPost方法中调用queryLifecycle.initialize初始化QueryLifecycle，使用UUID的方式生成唯一的queryId;</li>
<li>通过QueryLifecycle中的execute方法调用QueryPlus的run方法，然后调用BaseQuery的getQuerySegmentSpecForLookUp方法，最后调用QuerySegmentWalker(此处的实现是ClientQuerySegmentWalker)的getQueryRunnerForIntervals方法根据interval拆分子查询;</li>
</ul>
<p>QuerySegmentWalker主要是根据指定的interval/segment进行查询，是查询逻辑中比较重要的接口，它有以下几个比较重要的实现类：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ClientQuerySegmentWalker</span><br><span class="line">CachingClusteredClient</span><br><span class="line">ServerManager</span><br><span class="line">LuceneAppenderator</span><br></pre></td></tr></table></figure>

<ul>
<li>ClientQuerySegmentWalker：主要是在broker端使用，充当http-client的角色向his节点、task节点发出查询；</li>
<li>CachingClusteredClient：主要是在broker端配合ClientQuerySegmentWalker使用，在http-client查询前后添加缓存的逻辑；</li>
<li>ServerManager：主要是在his端使用，充当http-server的角色，根据client发起的查询，对本地的历史segment进行查询。</li>
<li>LuceneAppenderator：主要是在task端使用，充当http-server的角色，根据client发起的查询，对本地的实时segment进行查询。</li>
</ul>
<p>在ClientQuerySegmentWalker的decorateClusterRunner方法中构造FluentQueryRunner，并依次调用FluentQueryRunner的run、mergeResults方法进行查询请求分发、结果的合并。</p>
<h3 id="Historical查询流程"><a href="#Historical查询流程" class="headerlink" title="Historical查询流程"></a>Historical查询流程</h3><p>​    his端的查询流程主要是根据broker发过的请求，已经请求中的segmentId对本地的segment进行查询，并将查询返回给broker。需要注意的是his端的查询都是针对历史数据，实时接入的数据并不存放在his端。</p>
<h4 id="historical初始化"><a href="#historical初始化" class="headerlink" title="historical初始化"></a>historical初始化</h4><p>​    在开始理解historical的查询前，需要先了解historical的初始化过程。historical初始化相关代码主要在CliHistorical类中。</p>
<p>初始化过程主要加载了以下module:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CacheModule</span><br><span class="line">LookupModule</span><br><span class="line">MetricsModule</span><br><span class="line">LuceneDruidModule</span><br><span class="line">LuceneQueryCoreModule</span><br></pre></td></tr></table></figure>

<ul>
<li>CacheModule：主要用于查询结果的缓存；</li>
<li>LookupModule：主要用于分群id数据的读写；</li>
<li>MetricsModule：用于记录程序运行或查询中的相关指标；</li>
<li>LuceneDruidModule：主要用于适配Druid和Lucene的读写接口。</li>
<li>LuceneQueryCoreModule：主要是实现了基于Lucene的一些聚合器。</li>
</ul>
<h4 id="historical处理请求整体流程"><a href="#historical处理请求整体流程" class="headerlink" title="historical处理请求整体流程"></a>historical处理请求整体流程</h4><p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224146896.png" alt="image-20220211224146896"></p>
<p>​    his节点的查询流程和broker入口一致，通过QueryResource的dopost方法进入，区别在于这里的****QuerySegmentWalker*<em><strong>对象是由容器注入的，在broker端，会注入的walker为</strong></em>*ClientQuerySegmentWalker****，而在historcal端注入的walker为ServerManager。代码处理逻辑如下：</p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224212898.png" alt="image-20220211224212898"></p>
<p>​    由于在QueryWalker前的处理逻辑与broker的大致相同，这里的查询逻辑从ServerManager的getQueryRunnerForSegments方法开始说明，具体逻辑如下：</p>
<ol>
<li>在getQueryRunnerForSegments方法判断当前的查询类型，取出对应的QueryRunnerFactory和toolChest。</li>
</ol>
<p>​    1.1 QueryRunnerFactory的功能是创建底层查询的QueryRunner,以及合并多个QueryRunner的结果。该接口关注两个createRunner和mergeRunners两个方法：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">default</span> QueryRunner&lt;T&gt; <span class="title">createRunner</span><span class="params">(QueryAdapter queryAdapter)</span> </span></span><br><span class="line"><span class="function">QueryRunner&lt;T&gt; <span class="title">mergeRunners</span><span class="params">(ExecutorServicequeryExecutor, Iterable&lt;QueryRunner&lt;T&gt;&gt; queryRunners)</span></span>;</span><br></pre></td></tr></table></figure>

<ul>
<li><p> createRunner： 此方法传入一个入参QueryAdapter，基于给定的QueryAdapter创建一个QueryRunner,QueryRunner会对指定的QueryAdapter（可以看做成一个segment）进行查询，并且返回一个Sequence存储返回的结果。</p>
</li>
<li><p> mergeRunners：大部分场景下会查询多个segment，createRunner方法根据传入的QueryAdapter分片创建了QueryRunner,mergeRunner方法会将这些QueryRunner提交给ExecutorService并发执行，最后合并其返回结果。不同类型的查询设计了不同类型的QueryRunnerFactory,并且在LuceneDruidModule中绑定，如下图所示：</p>
</li>
</ul>
<p>  <img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224312529.png" alt="image-20220211224312529"></p>
<ol start="2">
<li>根据传入query里面的segment集合，QueryRunnerFactory给每个segment创建一个queryRunner去执行查询逻辑；</li>
</ol>
<p>​    2.1 QueryRunner是封装具体查询逻辑的高级接口,QueryRunner采用了装饰器设计模式，类似于jdk中io的实现，主要分为以下三类QueryRunner：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">通用的QueryRunner</span><br><span class="line">Broker用到的QueryRunner</span><br><span class="line">实时节点和历史节点用到的QueryRunner</span><br></pre></td></tr></table></figure>

<ul>
<li> 通用的QueryRunner</li>
</ul>
<p>MetricsEmittingQueryRunner:查询过程中收集相关的metric信息，并且发送到配置的Emitter。</p>
<p>CPUTimeMetricQueryRunner:查询过程中收集相关CPU的执行时间，并且发送打配置的Emitter。</p>
<p>FinalizeResultsQueryRunner:将复杂对象的metric转化为数值类型。</p>
<p>BySegmentQueryRunner:用于调试，在结果集上添加上Segment的信息。</p>
<ul>
<li> Broker用到的QueryRunner</li>
</ul>
<p>DirectDruidClient:使用HTTP对历史节点或者实时节点进行请求。</p>
<p>UnionQueryRunner:处理Union的请求</p>
<ul>
<li> 实时节点和历史节点用到的QueryRunner</li>
</ul>
<p>ChainedExecutionQueryRunner:并发查询的处理类，对不同的segment查询提供线程池处理，    并且将最后结果合并。</p>
<p>GroupByMergingQueryRunnerV2:类似于ChainedExecutionQueryRunner，由于groupby查    询最终合并需要通过根据维度分组聚合，所以需要单独使用这个类实现，同理FirstNQuery、    ScanQuery等也需要单独的实现，这里不做详细列举。</p>
<p>CachingQueryRunner:封装缓存的逻辑。</p>
<p>ReferenceCountingSegmentQueryRunner:添加对segment的引用计数逻辑，防止正在使用的segment被删除SpecificSegmentQueryRunner。</p>
<ol start="3">
<li><p>调用QueryRunnerFactory的mergeRunners方法将所有的queryRunner进行聚合</p>
</li>
<li><p>toolChest.mergeResults合并结果</p>
</li>
<li><p>返回最终的runner对象调用run方法进行查询</p>
</li>
</ol>
<h4 id="详细解析"><a href="#详细解析" class="headerlink" title="详细解析"></a>详细解析</h4><p>下面对getQueryRunnerForSegments方法进行一个解析：</p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224501518.png" alt="image-20220211224501518"></p>
<p>首先会获取QueryRunnerFactory，在druid中，每种查询类型都有属于自己的QueryRunnerFactory，并且这些factory都是单例对象，并且通过guice注入，这里conglomerate.findFactory(query);就是通过query类型获取对应的QueryRunnerFactory。</p>
<p>在QueryRunnerFactory这个接口中有三个方法</p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224514503.png" alt="image-20220211224514503"></p>
<ul>
<li> createRunner：通过传入一个queryAdapter对象返回一个QueryRunner。queryAdapter字面意思为查询适配，实际上代表一个segment引用，一个queryAdapter对象实际上就表示一个segment，其返回的QueryRunner中就包含了对这个segment的查询逻辑。</li>
<li> mergeRunners：此方法包含两个参数，queryExecutor表示执行查询的线程池，queryRunners则就是createRunner生成的QueryRunner集合，一般情况下在查询时候会有多个segment段一起并发执行查询，mergeRunners方法就是执行这些查询的入口。</li>
<li> getToolchest：此方法用于获取对应查询类型的QueryToolChest，每一个查询类型都有自己对应的QueryToolChest，QueryToolChest对象也是单例对象并且通过guice注入。</li>
</ul>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224539528.png" alt="image-20220211224539528"></p>
<p>​    这部分是构建queryRunners，每有一个segment都会对应有一个queryrunner,这里主要调用了buildAndDecorateQueryRunner方法来构建queryrunner，下面看看这个方法体中的实现：</p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224551432.png" alt="image-20220211224551432"></p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224555448.png" alt="image-20220211224555448"></p>
<p>初始化SpecificSegmentSpec：表示一个segment的唯一标识，可以获取segment的interval、segmentid等</p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224614911.png" alt="image-20220211224614911"></p>
<p>通过包装器模式构建整个执行链条，最终返回SetAndVerifyContextQueryRunner。如CachingQueryRunner中入参会传入metricsEmittingQueryRunner，而在CachingQueryRunner的run方法中：</p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224626074.png" alt="image-20220211224626074"></p>
<p>执行判断判定未开启populateCache的话会直接调用base.run(queryPlus, responseContext)，而base对象则是传入的ueryRunner。</p>
<p>在构建完成所有segment的QueryRunner之后，会将所有的QueryRunner进行一个合并：</p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224637342.png" alt="image-20220211224637342"></p>
<p>​    通过调用factory.mergeRunners对上一步生成的QueryQunners构建执行计划并且调用toolChest的mergeResults方法对结果进行再次的聚合，其实到最后整个查询的入口点就在toolChest.mergeResults方法中。</p>
<p>toolChest.mergeResults(factory.mergeRunners(exec, queryRunners))这段代码就可以看出查询的执行流程了，其中exec是一个线程池，线程池的数量通过参数druid.processing.numThreads设定，表示可用于并行处理段的处理线程数。我们的经验法则是num_cores-1，这意味着即使在重载情况下，仍有一个core可用于执行后台任务，如与ZooKeeper交谈和拉下片段。如果只有一个core可用，则此属性的默认值为1。建议设置为cpu核数减1。</p>
<p>​    针对与不同的查询类型，其构建的queryRunner对象不同，queryRunner其实可以看做一个函数，这些流程其实都是在构建queryRunner的执行链条，最终都是由QueryPlus的run方法来触发这些queryRunner执行。</p>
<h4 id="realtime节点查询流程"><a href="#realtime节点查询流程" class="headerlink" title="realtime节点查询流程"></a>realtime节点查询流程</h4><p>​    流程前部分和his、broker一样，只是segmentwalker不同，在realtime节点，使用的是RealtimeManager，现在看看它的getQueryRunnerForIntervals方法：</p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224735832.png" alt="image-20220211224735832"></p>
<p>​    相比his节点来说简单多了，其中关键在于fireChief.getQueryRunner(query)这里。FireChief是实时接入数据的一个线程，用于实时的接入数据，getQueryRunner如下：</p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224747937.png" alt="image-20220211224747937"></p>
<p>​    最终调用的是plumber.getQueryRunner(query)，其中plumber是接入数据的任务抽象，在实时接入任务时他的实现为AppenderatorPlumber，可以看做一个可追加数据的segment,对应QuerySegmentWalker为LuceneAppenderator。在LuceneAppenderator.getQueryRunnerForSegments方法中封装了具体逻辑，跟his逻辑类似这里不做详细阐述，请自行查看。</p>
<h4 id="join查询流程"><a href="#join查询流程" class="headerlink" title="join查询流程"></a>join查询流程</h4><p>join的详细设计可以参考社区的proposal:</p>
<p><a target="_blank" rel="noopener" href="https://gist.github.com/gianm/39548daef74f0373b3c87056e3db4627">https://gist.github.com/gianm/39548daef74f0373b3c87056e3db4627</a></p>
<p>总体而言，druid由于使用的是scatter-gather查询模型，目前druid会把join转化为子查询。</p>
<p>以 select * from A join B 为例，在druid中会转化为select * from A join (select * from B)。该查询的处理流程如下：</p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224839104.png" alt="image-20220211224839104"></p>
<h5 id="broker处理流程"><a href="#broker处理流程" class="headerlink" title="broker处理流程"></a>broker处理流程</h5><p>​    druid的join需要先经过broker节点，把维表的数据全部查询出来放置到内存中，转化为InlineDataSource,然后再广播到主表进行Join查询。因为需要用到druid的内存保存维表的数据，所以维表数据量不能太大，一般不建议超过10万。join在broker节点的时序图如下：</p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224911363.png" alt="image-20220211224911363"></p>
<p>​    关键逻辑是在ClientQuerySegmentWalker的inlineIfNecessary方法，该方法主要是进行维表的子查询并构建InlineDataSource,以便进行join过滤。</p>
<p>​    InlineDataSource是一个在内存中存放所有数据的数据源，本质是一个迭代器Iterable，在查询时会利用该迭代器在his端做过滤。</p>
<h5 id="his处理流程"><a href="#his处理流程" class="headerlink" title="his处理流程"></a>his处理流程</h5><p>​    druid的join在historical节点主要是将broker端生成InlineDataSource转化为RowBasedIndexedTable，然后在HashJoinEngine构建JoinMatcher对主表进行过滤。</p>
<p><img src="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/image-20220211224946026.png" alt="image-20220211224946026"></p>
<p>​    时序图中以TimeseriesQuery查询作为例子，其他类型的查询差别不大。</p>
<p>​    基本原理是将RowBasedIndexedTable的内存数据根据Join条件构建IndexedTableJoinMatcher，根据matchCondition方法判定是否满足连接条件。判定方式是提前将维表数据转化为一个Map，然后利用维表的数据进行key过滤，得到主表的docId。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>​    本文重点结合源码以及架构解析了druid在查询过程中执行流程，详细的分解了各个步骤关键点，如有疑问，可以联系笔者邮箱：<a href="mailto:&#55;&#x33;&#x31;&#x30;&#51;&#x30;&#x35;&#x37;&#x36;&#x40;&#113;&#113;&#46;&#99;&#x6f;&#x6d;">&#55;&#x33;&#x31;&#x30;&#51;&#x30;&#x35;&#x37;&#x36;&#x40;&#113;&#113;&#46;&#99;&#x6f;&#x6d;</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/" data-id="ckzijrjzg0000xf7918fs7h4g" data-title="APACHE DRUID 查询过程源码解析" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/druid/" rel="tag">druid</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-flink的内存管理机制简单解析" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/01/29/flink%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6%E7%AE%80%E5%8D%95%E8%A7%A3%E6%9E%90/" class="article-date">
  <time class="dt-published" datetime="2022-01-29T13:33:10.000Z" itemprop="datePublished">2022-01-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2022/01/29/flink%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6%E7%AE%80%E5%8D%95%E8%A7%A3%E6%9E%90/">Flink内存管理源码解读</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <blockquote>
<p>flink版本1.13</p>
</blockquote>
<pre><code>  在分布式计算引擎中，不管是flink、spark，mr等等使用jvm作为载体实现的框架中，对于整体的内存管理是一个很重要的部分，在大数据量下如何保证合理的使用，稳定的运行是各个框架的重点，本文将探究flink是如何对程序的内存进行一个管理。
</code></pre>
<p>从官网可以很直观和的看到flink的内存模型（本文只讲解taskmanager）</p>
<img src="https://nightlies.apache.org/flink/flink-docs-release-1.13/fig/detailed-mem-model.svg" alt="detailed-mem-model.svg" style="zoom:25%;" />

<p>可见flink在尽可能的尝试使用堆外内存来进行运算，都知道在jvm里面对内存的管理是自动的，在频繁的创建销毁对象的时候，监控分配都不是一件容易的事情，并且在堆类进行过度使用很容易造成oom等异常，所以需要对内存管理这一块进行一个特定的一个管理，而不能完全依靠jvm的内存回收机制。所以从底层上看，flink对内存的管理更像是cpp而不是java。</p>
<p>flink对内存管理大部分依靠组件<code>MemoryManager</code>，从源码中的注释我们可以得知<code>MemoryManager</code>主要完成的工作，如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * The memory manager governs the memory that Flink uses for sorting, hashing, caching or off-heap</span></span><br><span class="line"><span class="comment"> * state backends (e.g. RocksDB). Memory is represented either in&#123;<span class="doctag">@linkMemorySegment</span>&#125;s of equal</span></span><br><span class="line"><span class="comment"> * size or in reserved chunks of certain size. Operators allocate the memory either by requesting a</span></span><br><span class="line"><span class="comment"> * number of memory segments or by reserving chunks. Any allocated memory has to be released to be</span></span><br><span class="line"><span class="comment"> * reused later.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *&lt;p&gt;The memory segments are represented as off-heap unsafe memory regions (both via&#123;<span class="doctag">@link</span></span></span><br><span class="line"><span class="comment"> *MemorySegment&#125;). Releasing a memory segment will make it re-claimable by the garbage collector,</span></span><br><span class="line"><span class="comment"> * but does not necessarily immediately releases the underlying memory.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MemoryManager</span></span>&#123;&#125;</span><br></pre></td></tr></table></figure>

<p>可以得知MemoryManager工作为：</p>
<blockquote>
<p>MemoryManager管理Flink用于排序、hash、缓存或堆外状态后端（例如RocksDB）的内存。内存可以用大小相等的{@link MemorySegment}表示，也可以用一定大小的保留块表示。操作员通过请求大量内存段或保留块来分配内存。任何分配的内存都必须释放，以便以后重新使用。</p>
</blockquote>
<p>可以看到注释可得，flink对内存的操作非常谨慎，使用者在使用之前需要申请分配内存，使用完成之后必须要手动释放。</p>
<p><code>MemoryManager</code> 会在taskmanager启动的时候初始化，<code>MemoryManager</code> 数量取决于taskmanager一共有多少个<code>TaskSlot</code> 每一个TaskSlot都会有一个<code>MemoryManager</code>  </p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">TaskSlot</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function"><span class="keyword">final</span> <span class="keyword">int</span> index,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="keyword">final</span> ResourceProfile resourceProfile,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="keyword">final</span> <span class="keyword">int</span> memoryPageSize,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="keyword">final</span> JobID jobId,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="keyword">final</span> AllocationID allocationId,</span></span></span><br><span class="line"><span class="params"><span class="function">        <span class="keyword">final</span> Executor asyncExecutor)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">this</span>.index = index;</span><br><span class="line">    <span class="keyword">this</span>.resourceProfile = Preconditions.checkNotNull(resourceProfile);</span><br><span class="line">    <span class="keyword">this</span>.asyncExecutor = Preconditions.checkNotNull(asyncExecutor);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.tasks = <span class="keyword">new</span> HashMap&lt;&gt;(<span class="number">4</span>);</span><br><span class="line">    <span class="keyword">this</span>.state = TaskSlotState.ALLOCATED;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.jobId = jobId;</span><br><span class="line">    <span class="keyword">this</span>.allocationId = allocationId;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.memoryManager =createMemoryManager(resourceProfile, memoryPageSize);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">this</span>.closingFuture = <span class="keyword">new</span> CompletableFuture&lt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> MemoryManager <span class="title">create</span><span class="params">(<span class="keyword">long</span> memorySize, <span class="keyword">int</span> pageSize)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> MemoryManager(memorySize, pageSize);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到创建<code>MemoryManager</code> 会传入两个参数，一个是memorySize一个是pageSize，两个参数分别标识 <code>MemoryManager</code>  所管理的总的memorySize一个是pageSize。其中pageSize默认为32kb。</p>
<blockquote>
<p>pageSize是什么？</p>
</blockquote>
<p>程序在运行时往操作系统申请内存时，是一个一个page申请的，每一个page的大小是固定的，flink在这里借鉴了这一思想将内存申请也抽象为此，所以<code>MemoryManager</code> 对象中最终要的两个变量就是总内存大小和pageSize（每申请一块内存的大小）</p>
<p>之前就已经提过了<code>MemoryManager</code> 会申请内存，其实就是申请一块一块pageSize大小的内</p>
<p>pageSize，flink内部将这个每一块内存抽象为了<code>MemorySegment</code> 对象，<code>MemoryManager</code> 申请内存的方法为</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> List&lt;MemorySegment&gt; <span class="title">allocatePages</span><span class="params">(Object owner, <span class="keyword">int</span> numPages)</span></span></span><br><span class="line"><span class="function"><span class="keyword">throws</span> MemoryAllocationException</span>&#123;</span><br><span class="line">List&lt;MemorySegment&gt;segments = <span class="keyword">new</span> ArrayList&lt;&gt;(numPages);</span><br><span class="line">    allocatePages(owner, segments, numPages);</span><br><span class="line">    <span class="keyword">return</span> segments;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>其中numPages就是本次申请要申请的segment数量，返回的也是numPages个segment的集合，每一个segment代表的内存大小就是之前的pageSize</p>
<p>接下来看看<code>MemorySegment</code> 对象</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">@Nullable</span> <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">byte</span>[] heapMemory;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Nullable</span> <span class="keyword">private</span> ByteBuffer offHeapBuffer;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">long</span> address;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">long</span> addressLimit;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> size;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Nullable</span> <span class="keyword">private</span> <span class="keyword">final</span> Object owner;</span><br><span class="line"></span><br><span class="line"><span class="meta">@Nullable</span> <span class="keyword">private</span> Runnable cleaner;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>其中heapMemory和offHeapBuffer就是<code>MemorySegment</code> 所管理的内存，offHeapBuffer从字面意思就能看出来是表示堆外的内存 而heapMemory则表示堆内</p>
<p><code>MemorySegmentFactory</code> 是创建<code>MemorySegment</code> 的工厂，它可以创建基于堆内的 也可以创建堆外的内存</p>
<p>创建堆外的Memory</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> MemorySegment <span class="title">allocateOffHeapUnsafeMemory</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function"><span class="keyword">int</span> size, Object owner, Runnable customCleanupAction)</span> </span>&#123;</span><br><span class="line"><span class="keyword">long</span> address = MemoryUtils.allocateUnsafe(size);</span><br><span class="line">    ByteBuffer offHeapBuffer = MemoryUtils.wrapUnsafeMemoryWithByteBuffer(address, size);</span><br><span class="line">    Runnable cleaner = MemoryUtils.createMemoryCleaner(address, customCleanupAction);</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> MemorySegment(offHeapBuffer, owner, <span class="keyword">false</span>, cleaner);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>堆内</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> MemorySegment <span class="title">allocateUnpooledSegment</span><span class="params">(<span class="keyword">int</span> size, Object owner)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> <span class="keyword">new</span> MemorySegment(<span class="keyword">new</span> <span class="keyword">byte</span>[size], owner);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到申请堆外内存需要传入一个cleaner对象，它适用于内存用完之后对内存进行一个回收，而堆内则不需要，他由jvm虚拟机自动进行一个回收。</p>
<p>flink在什么地方使用这些内存？</p>
<ol>
<li><code>NetworkBuffer</code> ：flink在进行网络传输使用，每一个taskmanager在启动的时候都会生成一个<code>NetworkBufferPool</code>，在生成<code>NetworkBufferPool</code>时，会申请一定数量的内存用于网络传输，申请代码如下：</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numberOfSegmentsToAllocate; i++) &#123;</span><br><span class="line">availableMemorySegments.add(</span><br><span class="line">MemorySegmentFactory.allocateUnpooledOffHeapMemory(segmentSize, <span class="keyword">null</span>));</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>  其中申请的segmentSize为numberOfSegmentsToAllocate，每一块的大小为segmentSize，flink网络算子之间的数据传输就是依靠这些申请而来的内存，这两个参数是怎么来的呢？是通过对最大的网络内存除以pagesize分别得到的segmentSize就等于segmentSize 最大网络内存可以通过参数taskmanager.memory.network.fraction指定。而且可以看allocateUnpooledOffHeapMemory方法申请的是堆外内存，说明flink网络传输所使用的内存是堆外内存,并且这些内存在申请的时候，并不像之前allocateOffHeapUnsafeMemory 方法那样需要生成一个cleaner 对象，说明这些网络内存申请了就不用销毁而是伴随着taskmanager的整个生命周期</p>
<p>同理，在taskmanager中还有其他在taskmanager一初始化就申请内存并且伴随整个taskmanager生命周期的segmentbufferpool，具体代码我不过度介绍了。如：</p>
<p><code>BatchShuffleReadBufferPool： **一个固定大小的 MemorySegment池，由批处理用于shuffle数据读取**</code></p>
<ol>
<li>状态后端和python的UDf，RocksDB State Backend 的本地内存，flink在使用rocksdb作为状态后端存储的时候rocksdb会使用这部分内存。同时python的UDF也使用的是这部分的内存，他们申请内存都是通过MemoryManager 的getSharedMemoryResourceForManagedMemory方法，这里不做详细说明，感兴趣的可以看一下这部分源码，</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span>&lt;T extends AutoCloseable&gt;</span><br><span class="line">OpaqueMemoryResource&lt;T&gt;getSharedMemoryResourceForManagedMemory(</span><br><span class="line">String type,</span><br><span class="line">                LongFunctionWithException&lt;T, Exception&gt;initializer,</span><br><span class="line">                <span class="keyword">double</span> fractionToInitializeWith)</span><br><span class="line"><span class="keyword">throws</span> Exception&#123;&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>批处理中的排序，分组和缓存部分，上面已经说过，每个slot都会分配一个MemoryManager ，而在task运行过程中，在批处理中，往往存在对大量数据进行排序或者分组的操作，这些操作需要申请一定数量的内存进行。也会通过MemoryManager 进行内存的申请。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/01/29/flink%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6%E7%AE%80%E5%8D%95%E8%A7%A3%E6%9E%90/" data-id="ckyzvppji0000hg9jf88v84s4" data-title="Flink内存管理源码解读" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/flink/" rel="tag">flink</a></li></ul>

    </footer>
  </div>
  
</article>



  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/druid/" rel="tag">druid</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/flink/" rel="tag">flink</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/druid/" style="font-size: 20px;">druid</a> <a href="/tags/flink/" style="font-size: 10px;">flink</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2022/02/19/druid%E4%B8%ADGroupbyQuery%E6%9F%A5%E8%AF%A2%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/">druid中GroupbyQuery查询流程解析</a>
          </li>
        
          <li>
            <a href="/2022/02/19/druid%E4%B8%ADTimeseriesQuery%E7%9A%84%E6%9F%A5%E8%AF%A2%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/">druid中TimeseriesQuery的查询源码解析</a>
          </li>
        
          <li>
            <a href="/2022/02/19/druid%E4%B8%AD%E7%9A%84%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB/">druid中的常用工具类</a>
          </li>
        
          <li>
            <a href="/2022/02/11/APACHE-DRUID-%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/">APACHE DRUID 查询过程源码解析</a>
          </li>
        
          <li>
            <a href="/2022/01/29/flink%E7%9A%84%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%9C%BA%E5%88%B6%E7%AE%80%E5%8D%95%E8%A7%A3%E6%9E%90/">Flink内存管理源码解读</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 Lime<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>